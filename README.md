# GA-optimized-regression-models
Regression Models Enhanced with Genetic Algorithm Optimization(Machine learning)
# GA-Optimized Regression Models

This project demonstrates how **Genetic Algorithms (GA)** can be used to improve the performance of various **regression models** by tuning their coefficients and hyperparameters. The analysis is based on a synthetic dataset of student study hours and exam scores.

## ğŸ“Š Dataset

The dataset contains 1,000 samples with:

* `Hours`: Number of hours studied
* `Scores`: Exam score (out of 100)

## ğŸ§  Models Used

* Linear Regression
* Polynomial Regression (degree selected via GA)
* Ridge Regression
* Lasso Regression
* Decision Tree Regressor
* Random Forest Regressor

## ğŸ§¬ Role of Genetic Algorithm

The GA was used to:

* Optimize model coefficients (w, b)
* Dynamically select the best polynomial degree (1 to 6)
* Tune hyperparameters like alpha (Ridge/Lasso), depth (Decision Tree), and number of estimators (Random Forest)

## ğŸ§ª Evaluation Metrics

* MAE (Mean Absolute Error)
* MSE (Mean Squared Error)
* RMSE (Root Mean Squared Error)
* RÂ² Score (Coefficient of Determination)

## ğŸš€ Key Results

* Polynomial Regression (degree 3) had the best RÂ² before GA.
* After GA, Random Forest gave the best accuracy.
* GA-tuned models performed better overall in terms of RMSE and RÂ².
* No overfitting detected: training and test scores were close.

## ğŸ“ Files

* `task1.ipynb`: Main notebook with all code and analysis
* `task1.pdf`: Project report
* `expanded_data.xlsx`: Synthetic dataset used

## ğŸ“Œ Conclusion

Genetic Algorithms can significantly improve the accuracy of regression models by intelligently tuning their parameters. Random Forest and GA-optimized Lasso Regression achieved the best performance in this project.

---

Feel free to explore and build upon this work. â­  Ø§Ù†Ø³Ø® Ø¯Ø§ ÙÙŠ Ø¬Ø²Ø¡ Ø§Ù„ÙƒÙˆØ¯ ÙˆÙ„Ø§ Ø§Ù„ previwe?
